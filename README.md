# facial_keypoints



![test](https://user-images.githubusercontent.com/61696612/75885803-d77d2c00-5e2f-11ea-9574-7cbe971aeffc.png)


## Thesis Abstract
  The main goal of this thesis is the implementation and analysis of deep neural networks
to be applied to image feature extraction scenarios, utilizing convolutional layers. To be precise,
this project covers the implementation of models, capable of detecting and extracting features
from human faces. Facial key-point detection is a computer vision task and is a very
powerful tool in the analysis of human emotion, as well as digital face processing using
graphics. Ultimately the models implemented, detect the coordinates of a personâ€™s mouth,
eyes, lips, and nose in any given facial portrait.

  After a short introduction to Computer Vision and the impact of artificial neural
networks on the field, an in-depth analysis of a Machine Learning (ML) approach to the facial
feature extraction problem is made. Furthermore, thorough presentations of Convolutional
Neural Networks (CNN) and their various architectures are provided.
 
  Next, the implementations of the image pre-processing and dataset expansion
algorithms necessary to achieve efficient network training are given, followed by the CNN
architectures that were used. The different approaches were then evaluated on their
performance on the same dataset. In specific, the first network is inspired by the sequential
model LeNet, and the second one is a functional model inspired by ResNet-50 way deeper than
the previous one. The results of these models, as well as how they become efficient, are
examined.

  Python programming language is used for pre-processing and model creation, together
with TensorFlow and Keras frameworks, which are considered to be the best tools, at the
moment, for Deep Neural Network implementations. Facial detection from image or video is
handled by the OpenCV Python library. Eventually, the models implemented are applied in
several portrait images to extract the desired features.

